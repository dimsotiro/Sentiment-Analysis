{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3bd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  label                                              tweet\n",
      "0   1      0   @user when a father is dysfunctional and is s...\n",
      "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  #model   i love u take with u all the time in ...\n",
      "4   5      0             factsguide: society now    #motivation\n",
      "Class distribution:\n",
      " label\n",
      "0    29720\n",
      "1     2242\n",
      "Name: count, dtype: int64\n",
      "Rows: 31962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    accuracy_score\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df = pd.read_csv(/train.csv\")\n",
    "\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(\"Class distribution:\\n\", df['label'].value_counts())\n",
    "print(\"Rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac7412",
   "metadata": {},
   "source": [
    "## 2) Basic Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645f1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit i can t use cause they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0   @user when a father is dysfunctional and is s...   \n",
       "1  @user @user thanks for #lyft credit i can't us...   \n",
       "2                                bihday your majesty   \n",
       "3  #model   i love u take with u all the time in ...   \n",
       "4             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  when a father is dysfunctional and is so selfi...  \n",
       "1  thanks for lyft credit i can t use cause they ...  \n",
       "2                                bihday your majesty  \n",
       "3      model i love u take with u all the time in ur  \n",
       "4                  factsguide society now motivation  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tweet(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove mentions (@user, @someone123)\n",
    "    text = re.sub(r'@\\w+', ' ', text)\n",
    "    \n",
    "    # remove urls\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)\n",
    "    \n",
    "    # replace html entities\n",
    "    text = text.replace('&amp;', ' and ')\n",
    "    \n",
    "    # remove hashtags symbol but keep the word ( #love -> love )\n",
    "    text = re.sub(r'#', ' ', text)\n",
    "    \n",
    "    # remove numbers and punctuation and emojis (keep only letters + spaces)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    \n",
    "    # collapse multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# apply to your df\n",
    "df['clean_tweet'] = df['tweet'].apply(clean_tweet)\n",
    "\n",
    "df[['tweet', 'clean_tweet']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83745994",
   "metadata": {},
   "source": [
    "## 3) Stopwards cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254abbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dimso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit i can t use cause they ...</td>\n",
       "      <td>thanks lyft credit use cause offer wheelchair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model i love u take with u all the time in ur</td>\n",
       "      <td>model love u take u time ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0   @user when a father is dysfunctional and is s...   \n",
       "1  @user @user thanks for #lyft credit i can't us...   \n",
       "2                                bihday your majesty   \n",
       "3  #model   i love u take with u all the time in ...   \n",
       "4             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when a father is dysfunctional and is so selfi...   \n",
       "1  thanks for lyft credit i can t use cause they ...   \n",
       "2                                bihday your majesty   \n",
       "3      model i love u take with u all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                  clean_tweet_nostop  \n",
       "0  father dysfunctional selfish drags kids dysfun...  \n",
       "1  thanks lyft credit use cause offer wheelchair ...  \n",
       "2                                     bihday majesty  \n",
       "3                        model love u take u time ur  \n",
       "4                      factsguide society motivation  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['clean_tweet_nostop'] = df['clean_tweet'].apply(remove_stopwords)\n",
    "\n",
    "df[['tweet', 'clean_tweet', 'clean_tweet_nostop']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6cc180",
   "metadata": {},
   "source": [
    "## Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1853e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_tweet_nostop']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# For collecting results\n",
    "results = []\n",
    "\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    \"\"\"Print detailed metrics and store summary in results.\"\"\"\n",
    "    print(f\"\\n## {name} ##\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    f1_c1 = f1_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"f1_class1\": f1_c1,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"accuracy\": acc\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617fe0a",
   "metadata": {},
   "source": [
    "# MODEL 1: NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268e8392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Naive Bayes ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      5945\n",
      "           1       0.97      0.25      0.40       448\n",
      "\n",
      "    accuracy                           0.95      6393\n",
      "   macro avg       0.96      0.63      0.69      6393\n",
      "weighted avg       0.95      0.95      0.93      6393\n",
      "\n",
      "Confusion matrix:\n",
      "[[5942    3]\n",
      " [ 335  113]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_nb = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_nb = tfidf_nb.fit_transform(X_train)\n",
    "X_valid_nb = tfidf_nb.transform(X_valid)\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_nb, y_train)\n",
    "\n",
    "y_pred_nb = nb_clf.predict(X_valid_nb)\n",
    "evaluate_model(\"Naive Bayes\", y_valid, y_pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff3898",
   "metadata": {},
   "source": [
    "# MODEL 2: LOGISTIC REGRESSION (BALANCED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa3a51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Logistic Regression (balanced) ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      5945\n",
      "           1       0.54      0.78      0.64       448\n",
      "\n",
      "    accuracy                           0.94      6393\n",
      "   macro avg       0.76      0.86      0.80      6393\n",
      "weighted avg       0.95      0.94      0.94      6393\n",
      "\n",
      "Confusion matrix:\n",
      "[[5651  294]\n",
      " [ 100  348]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_lr = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_lr = tfidf_lr.fit_transform(X_train)\n",
    "X_valid_lr = tfidf_lr.transform(X_valid)\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "log_reg.fit(X_train_lr, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_valid_lr)\n",
    "evaluate_model(\"Logistic Regression (balanced)\", y_valid, y_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6098ad",
   "metadata": {},
   "source": [
    "# MODEL 3: SVC + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "140d4d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## SMOTE Info ##\n",
      "Before SMOTE class balance:\n",
      " label\n",
      "0    23775\n",
      "1     1794\n",
      "Name: count, dtype: int64\n",
      "After SMOTE class balance:\n",
      " label\n",
      "0    23775\n",
      "1    23775\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dimso\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## SVC + SMOTE ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      5945\n",
      "           1       0.48      0.74      0.58       448\n",
      "\n",
      "    accuracy                           0.92      6393\n",
      "   macro avg       0.73      0.84      0.77      6393\n",
      "weighted avg       0.94      0.92      0.93      6393\n",
      "\n",
      "Confusion matrix:\n",
      "[[5582  363]\n",
      " [ 118  330]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_svm_smote = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_svm = tfidf_svm_smote.fit_transform(X_train)\n",
    "X_valid_svm = tfidf_svm_smote.transform(X_valid)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train_svm, y_train)\n",
    "\n",
    "print(\"\\n## SMOTE Info ##\")\n",
    "print(\"Before SMOTE class balance:\\n\", y_train.value_counts())\n",
    "print(\"After SMOTE class balance:\\n\", pd.Series(y_train_res).value_counts())\n",
    "\n",
    "svc_smote = LinearSVC()\n",
    "svc_smote.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred_svm_smote = svc_smote.predict(X_valid_svm)\n",
    "evaluate_model(\"SVC + SMOTE\", y_valid, y_pred_svm_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f1c060",
   "metadata": {},
   "source": [
    "# MODEL 4: SVC + CALIBRATED PROBABILITIES + THRESHOLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdd90083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Best Threshold for SVC + Calibrated ##\n",
      "Best threshold: 0.350, best F1(class 1): 0.7179\n",
      "\n",
      "## SVC + Calibrated (thr=0.350) ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      5945\n",
      "           1       0.75      0.69      0.72       448\n",
      "\n",
      "    accuracy                           0.96      6393\n",
      "   macro avg       0.86      0.84      0.85      6393\n",
      "weighted avg       0.96      0.96      0.96      6393\n",
      "\n",
      "Confusion matrix:\n",
      "[[5843  102]\n",
      " [ 140  308]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_svc_thr = TfidfVectorizer(\n",
    "    max_features=20000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "X_train_thr = tfidf_svc_thr.fit_transform(X_train)\n",
    "X_valid_thr = tfidf_svc_thr.transform(X_valid)\n",
    "\n",
    "svc_base = LinearSVC(class_weight='balanced', dual='auto')\n",
    "svc_cal = CalibratedClassifierCV(svc_base, cv=3, method=\"sigmoid\")\n",
    "svc_cal.fit(X_train_thr, y_train)\n",
    "\n",
    "proba_valid = svc_cal.predict_proba(X_valid_thr)[:, 1]\n",
    "\n",
    "best_thr = 0.5\n",
    "best_f1 = 0.0\n",
    "\n",
    "for thr in np.linspace(0.2, 0.8, 25):\n",
    "    y_pred_thr_loop = (proba_valid >= thr).astype(int)\n",
    "    f1 = f1_score(y_valid, y_pred_thr_loop, pos_label=1, zero_division=0)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thr = thr\n",
    "\n",
    "print(f\"\\n## Best Threshold for SVC + Calibrated ##\")\n",
    "print(f\"Best threshold: {best_thr:.3f}, best F1(class 1): {best_f1:.4f}\")\n",
    "\n",
    "y_pred_thr = (proba_valid >= best_thr).astype(int)\n",
    "evaluate_model(f\"SVC + Calibrated (thr={best_thr:.3f})\", y_valid, y_pred_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0292d65d",
   "metadata": {},
   "source": [
    "# Summary Table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e0121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "## SUMMARY TABLE (sorted by F1 for class 1) ##\n",
      "                         model  f1_class1  f1_macro  accuracy\n",
      "  SVC + Calibrated (thr=0.350)   0.717949  0.848830  0.962146\n",
      "Logistic Regression (balanced)   0.638532  0.802423  0.938370\n",
      "                   SVC + SMOTE   0.578440  0.768567  0.924761\n",
      "                   Naive Bayes   0.400709  0.686527  0.947130\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df = summary_df.sort_values(by=\"f1_class1\", ascending=False)\n",
    "\n",
    "print(\"\\n\\n## SUMMARY TABLE (sorted by F1 for class 1) ##\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94ae17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b2952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a52d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a15c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b7871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa956d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f528dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7db13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a8b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c21ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eff535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
